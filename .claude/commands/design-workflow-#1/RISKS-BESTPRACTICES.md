# AI-Assisted Design Workflow: Risks & Best Practices

## Potential Risks for Designers

| # | Risk | What Happens | How to Mitigate |
|---|------|--------------|-----------------|
| 1 | **Over-Reliance** | Accept AI outputs as truth without critical thinking | Always validate with real research; challenge at least one assumption per output |
| 2 | **Context Loss** | Generic solutions that don't fit your specific product/users | Provide rich context; explicitly state what AI doesn't know; cross-check with internal data |
| 3 | **Confirmation Bias** | AI reinforces existing beliefs instead of challenging them | Ask AI to challenge your framing; run opposite assumptions; use "steelman" prompts |
| 4 | **False Precision** | Structured outputs create illusion of scientific rigor | Label outputs as "hypotheses to test"; add confidence intervals; run actual experiments |
| 5 | **Process Over Outcome** | Following 11 steps becomes goal instead of solving problem | Skip steps when appropriate; set time limits; exit early if answer is clear |
| 6 | **Team Disconnect** | Solo AI work creates outputs team hasn't bought into | Run key commands collaboratively; share raw outputs; use as discussion starters |
| 7 | **Privacy Leaks** | Sharing sensitive company/user data with AI systems | Anonymize all inputs; use fictional examples; check company AI policy |
| 8 | **Homogenization** | AI-driven design leads to similar solutions across companies | Add your unique spin; ask for unconventional alternatives; filter through brand principles |
| 9 | **Tech Feasibility Blindness** | AI suggests solutions without understanding constraints | Include tech constraints in input; review with engineering; prototype before building |
| 10 | **Vanity Metrics** | Metrics sound good but don't measure real value | Connect metrics to outcomes; ask "if this improves but users unhappy, why?"; validate qualitatively |
| 11 | **Validation Theater** | Going through motions without real learning | Pre-commit to falsification criteria; seek disconfirming evidence; be willing to kill ideas |
| 12 | **Speed vs. Depth** | Fast iteration skips necessary depth | Build in pause points for testing; schedule user research between steps; quality > quantity |

---

## Red Flags vs. Best Practices

| Red Flags (Stop and Reassess) | Best Practices (Healthy Habits) |
| :--- | :--- |
| You haven't talked to a real user in the last week. | Outputs reference specific user quotes or data from your actual research. |
| Your outputs are >80% AI-generated text with no customization. | You frequently disagree with and modify AI suggestions to fit your context. |
| Team members are surprised by your "research findings". | AI outputs spark team debates and encourage collaborative thinking. |
| You can't explain **WHY** you chose a framing beyond "the AI suggested it". | You can explain all decisions on their own merits without referencing the AI. |
| Stakeholders say the work "feels generic". | Solutions feel specific to YOUR product and stakeholders recognize their input. |
| You're on step 8 but haven't prototyped anything. | You iterate faster but validate just as rigorously as a manual process. |
| Engineers say "this is impossible" after your presentation. | Technical constraints are included in inputs and reviewed with engineering early. |
| Your hypothesis has never changed despite new information. | You use AI to identify blind spots and challenge your own assumptions. |
| You feel defensive when someone questions the approach. | AI is used as a thought partner to strengthen decision-making. |

---

### Remember
**AI is a thought partner and productivity tool**, not a replacement for:
* **Design judgment**
* **User empathy**
* **Collaborative decision-making**
* **Domain expertise**
* **Stakeholder alignment**

---

## Quick Reference

**Use AI for:**
* Generating diverse perspectives quickly
* Structuring messy thoughts
* Identifying blind spots
* Accelerating documentation

**Don't use AI for:**
* Final decision-making
* Replacing user research
* Validating assumptions
* Understanding your unique context

**Golden Rule:** If you can't defend a decision without saying "the AI suggested it," you're not ready to proceed.